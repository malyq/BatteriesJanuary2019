
<workflow-app name="spark-test" xmlns="uri:oozie:workflow:0.3">
       <start to="myFirstSparkJob"/>

	<action name="myFirstSparkJob">        
	<spark xmlns="uri:oozie:spark-action:0.1">
            <job-tracker>${resourceManager}</job-tracker>
            <name-node>${name_node}</name-node>
            <prepare>
               <delete path="${name_node}/root/HOutput"/>
              <!-- ...
               <mkdir path="[PATH]"/>
               ...-->
            </prepare>
           <!-- <job-xml>[SPARK SETTINGS FILE]</job-xml>
            <configuration>
                <property>
                    <name>[PROPERTY-NAME]</name>
                    <value>[PROPERTY-VALUE]</value>
                </property>
                ...
            </configuration>-->
            <master>local[*]</master>
            <mode>cluster</mode>
            <name>Spark Example</name>
            <class>com.revature.DriverYARN</class>
            <jar>${name_node}/user/root/HData/WordCountSpark.jar</jar> 
            <spark-opts>--jars ${name_node}/user/root/HData/WordCountSpark.jar</spark-opts>
    	    <!-- <arg>hdfs://localhost/HData/all-bible</arg> -->
	    <arg>${name_node}/user/root/HData/all-bible</arg>
            <arg>${name_node}/user/root/HOutput</arg>
	    <arg>200</arg>
		</spark>	
		<ok to="end" />
                <error to="kill" />
       </action>

        <!-- Kill Job Control Node -->
        <kill name="kill">
                <message>Oozie lab job terminated with errors.</message>
        </kill>

        <!-- End Job Control Node -->
        <end name="end" />

</workflow-app>
